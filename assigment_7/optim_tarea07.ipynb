{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"background-color: lightgray; padding: 20px; color: black;\">\n",
    "<div>\n",
    "<img src=\"https://th.bing.com/th/id/R.3cd1c8dc996c5616cf6e65e20b6bf586?rik=09aaLyk4hfbBiQ&riu=http%3a%2f%2fcidics.uanl.mx%2fwp-content%2fuploads%2f2016%2f09%2fcimat.png&ehk=%2b0brgMUkA2BND22ixwLZheQrrOoYLO3o5cMRqsBOrlY%3d&risl=&pid=ImgRaw&r=0\" style=\"float: right; margin-right: 30px;\" width=\"200\"/> \n",
    "<font size=\"6.9\" color=\"8C3061\"><b>Curso de Optimización</b></font> <br>\n",
    "<font size=\"4.5\" color=\"8C3061\"><b>Tarea 7 - Método de Newton con Gradiente Conjugado</b></font> \n",
    "</div>\n",
    "<div style=\"text-align: left\">  <br>\n",
    "Edison David Serrano Cárdenas. <br>\n",
    "MSc en Matemáticas Aplicadas <br>\n",
    "CIMAT - Sede Guanajuato <br>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Cargar Librerías**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from typing import Tuple, Callable \n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "\n",
    "# load module Opti_functions\n",
    "from opti_functions import Opti_functions as opti\n",
    "\n",
    "# load visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Ejercicio 1 (4.0 puntos)**</font>\n",
    "\n",
    "Programar el método de Newton truncado descrito en el Algoritmo 1 y 2 de la Clase 20.\n",
    "   \n",
    "1. Programar la función que implementa el Algoritmo 1, que calcula una aproximación\n",
    "   de la solución del sistema de Newton. \n",
    "- Haga que la función devuelva la dirección $\\mathbf{p}_k$ y el número de iteraciones realizadas.\n",
    "\n",
    "2. Programar la función que implementa el Algoritmo 2. \n",
    "- Use el algoritmo de backtracking con la condición de descenso suficiente para \n",
    "  calcular el tamaño de paso $\\alpha_k$.\n",
    "- Defina la variable binaria $res$ de modo que $True$ si se cumple la condición de salida\n",
    "  $\\|\\mathbf{g}_k\\|<\\tau$ y $False$ si termina por iteraciones.\n",
    "- Calcule el promedio de las iteraciones realizadas por el Algoritmo 1 \n",
    "- Haga que la función devuelva $\\mathbf{x}_k, \\mathbf{g}_k, k, res$ y el\n",
    "  promedio de la iteraciones realizadas por el Algoritmo 1.\n",
    "\n",
    "3. Pruebe el algoritmo para minimizar las siguientes funciones usando los parámetros\n",
    "   $N=5000$, $\\tau = \\sqrt{n}\\epsilon_m^{1/3}$, donde $n$ es la dimensión\n",
    "   de la variable $\\mathbf{x}$ y $\\epsilon_m$ es el épsilon máquina. \n",
    "   Para backtracking use $\\rho=0.5$, $c_1=0.001$ y el número máximo de iteraciones $N_b=500$.\n",
    "   \n",
    "   En cada caso imprima los siguientes datos:\n",
    "   \n",
    "- la dimensión $n$,\n",
    "- $f(\\mathbf{x}_0)$,\n",
    "- el  número $k$ de iteraciones realizadas,\n",
    "- $f(\\mathbf{x}_k)$,\n",
    "- las primeras y últimas 4 entradas del punto $\\mathbf{x}_k$ que devuelve el algoritmo,\n",
    "- la norma del vector gradiente $\\mathbf{g}_k$, \n",
    "- el promedio del número de iteraciones realizadas por el Algoritmo 1.\n",
    "- la variable $res$ para saber si el algoritmo puedo converger.\n",
    "  \n",
    "\n",
    "\n",
    "**Función de cuadrática 1:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "- $f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^\\top\\mathbf{A}_1\\mathbf{x} - \\mathbf{b}_1^\\top\\mathbf{x}$,\n",
    "  donde $\\mathbf{A}_1$ y $\\mathbf{b}_1$ están definidas por\n",
    "  \n",
    "\n",
    "$$ \\mathbf{A}_1 = n\\mathbf{I} + \\mathbf{1} = \n",
    "\\left[\\begin{array}{llll} n      & 0      & \\cdots & 0 \\\\\n",
    "                       0      & n      & \\cdots & 0 \\\\ \n",
    "                       \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                       0      & 0      & \\cdots & n \\end{array}\\right]\n",
    "+ \\left[\\begin{array}{llll} 1    & 1      & \\cdots & 1 \\\\\n",
    "                       1      & 1      & \\cdots & 1 \\\\ \n",
    "                       \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                       1      & 1      & \\cdots & 1 \\end{array}\\right],  \\qquad\n",
    "\\mathbf{b}_1 = \\left[\\begin{array}{l} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{array}\\right], $$\n",
    "\n",
    "donde $\\mathbf{I}$ es la matriz identidad y $\\mathbf{1}$ es la matriz llena de 1's,\n",
    "ambas de tamaño $n$, usando los puntos iniciales   \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ \n",
    "\n",
    "---\n",
    "\n",
    "**Función de cuadrática 2:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "- $f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^\\top\\mathbf{A}_2\\mathbf{x} - \\mathbf{b}_2^\\top\\mathbf{x}$,\n",
    "  donde $\\mathbf{A}_2= [a_{ij}]$ y $\\mathbf{b}_2$ están definidas por\n",
    "  \n",
    "$$ a_{ij} = exp\\left(-0.25(i-j)^2 \\right),  \\qquad\n",
    "\\mathbf{b}_2 = \\left[\\begin{array}{l} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{array}\\right] $$\n",
    "\n",
    "usando los puntos iniciales:\n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ \n",
    "\n",
    "---\n",
    "\n",
    "**Función de Beale :** Para $\\mathbf{x}=(x_1,x_2)$\n",
    "\n",
    "$$f(\\mathbf{x}) = (1.5-x_1 + x_1x_2)^2 + (2.25 - x_1 + x_1x_2^2)^2 + (2.625 - x_1 + x_1x_2^3)^2.$$\n",
    "- $\\mathbf{x}_0 = (2,3)$  \n",
    "   \n",
    "---\n",
    "\n",
    "**Función de Himmelblau:** Para $\\mathbf{x}=(x_1,x_2)$\n",
    "\n",
    "$$f(\\mathbf{x}) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2. $$\n",
    "- $\\mathbf{x}_0 = (2,4)$\n",
    "\n",
    "---\n",
    "\n",
    "**Función de Rosenbrock:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "$$ f(\\mathbf{x}) = \\sum_{i=1}^{n-1} \\left[100(x_{i+1} - x_i^2)^2 + (1-x_i)^2 \\right]\n",
    "\\quad n\\geq 2.$$\n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0)\\in \\mathbb{R}^{2}$  \n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{20}$  \n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{40}$ \n",
    "\n",
    "### Solución:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementación del algoritmo 1 de la clase 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient_to_Newton_system(hessk:np.array, \n",
    "                                        gk:np.array, \n",
    "                                        x0:np.array, \n",
    "                                        n:int, \n",
    "                                        tol:float)->Tuple[np.array, int]:\n",
    "    \"\"\"Conjugate gradient to solve Newton system\n",
    "    \n",
    "    :param hess: Hessian matrix (np.array)\n",
    "    :param gk: gradient vector (np.array)\n",
    "    :param x0: initial guess (np.array)\n",
    "    :param n: number of iterations (int)\n",
    "    :param tol: tolerance (float)\n",
    "    \n",
    "    :return: Tuple with solution and number of iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    z0 = np.zeros_like(x0)\n",
    "    r0 = gk\n",
    "    d0 = -r0\n",
    "    for j in range(n):\n",
    "        if d0.T @ hessk @ d0 <= 0:\n",
    "            if j==0:\n",
    "                return -gk, 0\n",
    "            else:\n",
    "                return z0, j\n",
    "        alpha = (r0@ r0) / (d0.T @ hessk @ d0)\n",
    "        z0 = z0 + alpha * d0\n",
    "        rj = r0 + alpha * hessk @ d0\n",
    "        beta = (rj @ rj) / (r0@ r0)\n",
    "        d0 = -rj + beta * d0\n",
    "        if np.linalg.norm(rj) < tol:\n",
    "            return z0, j+1\n",
    "        r0 = rj\n",
    "    return z0, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implementación del algoritmo 2 de la clase 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search_NewtonGC(f: Callable[[np.array], float],\n",
    "                         grad: Callable[[np.array], np.array],\n",
    "                            hess: Callable[[np.array], np.array],\n",
    "                            x0: np.array,\n",
    "                            tol: float,\n",
    "                            max_iter: int)->Tuple[np.array,np.array, int,bool,float]:\n",
    "    \n",
    "    \"\"\"Line search Newton with conjugate gradient\n",
    "    \n",
    "    :param f: objective function (Callable[[np.array], float])\n",
    "    :param grad: gradient function (Callable[[np.array], np.array])\n",
    "    :param hess: hessian function (Callable[[np.array], np.array])\n",
    "    :param x0: initial guess (np.array)\n",
    "    :param tol: tolerance (float)\n",
    "    :param max_iter: maximum number of iterations (int)\n",
    "    \n",
    "    :return: Tuple with solution, gradient, number of iterations, success flag and mean time for each conjugate_gradient_to_Newton_system\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x0)\n",
    "    mean_iter_alg1 = 0\n",
    "    for i in range(max_iter):\n",
    "        # compute gradient and hessian\n",
    "        gk = grad(x0)\n",
    "        if np.linalg.norm(gk) < tol:\n",
    "            if i==0:\n",
    "                return x0, gk, i, True, 0\n",
    "            return x0, gk, i, True, mean_iter_alg1 / i\n",
    "        \n",
    "        #compute hessian\n",
    "        hessk = hess(x0)\n",
    "        ek = min(0.5, np.sqrt(np.linalg.norm(gk)))*np.linalg.norm(gk)\n",
    "        pk,k = conjugate_gradient_to_Newton_system(hessk, gk, x0, n, tol)\n",
    "        mean_iter_alg1 += k\n",
    "        fk =f(x0)\n",
    "        alpha, _ = opti.back_tracking(alpha_init=1,rho=0.5,c=1e-3,\n",
    "                                   xk=x0,f=f,fk=fk,grad_fk=gk,\n",
    "                                   dir_pk=pk,iter_maxb=500)\n",
    "        # line search\n",
    "        x0 = x0 + alpha * pk\n",
    "    return x0, gk, i, False, mean_iter_alg1 / max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluación del algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_line_search_NewtonGC(f: Callable[[np.array], float],\n",
    "                            grad: Callable[[np.array], np.array],\n",
    "                            hess: Callable[[np.array], np.array],\n",
    "                            x0: np.array,\n",
    "                            tol: float,\n",
    "                            max_iter: int)->None:\n",
    "    \"\"\"Test line search Newton with conjugate gradient\n",
    "    \n",
    "    :param f: function\n",
    "    :param grad: gradient\n",
    "    :param hess: hessian\n",
    "    :param x0: initial guess\n",
    "    :param tol: tolerance\n",
    "    :param max_iter: maximum number of iterations\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    xk, gk, n_iter, flag, mean_iter_alg1 = line_search_NewtonGC(f,grad,hess,x0,tol,max_iter)\n",
    "    n = x0.shape[0]\n",
    "    print(f\"Dimensión:\\t\\t{n}\")\n",
    "    print(f\"f(x0):\\t\\t\\t{f(x0)}\")\n",
    "    print(f\"Número de iteraciones:\\t{n_iter}\")\n",
    "    print(f\"f(xk):\\t\\t\\t{f(xk)}\")\n",
    "    if n <10:\n",
    "        print(\"Solución:\\t\\t\",xk)\n",
    "    else:\n",
    "        print(\"Solución:\\t\\t\",','.join(map(str, xk[:4])),\",...,\",','.join(map(str, xk[-4:])))\n",
    "    \n",
    "    print(\"||gk||:\\t\\t\\t\",np.linalg.norm(gk))\n",
    "    print(\"Iter. promedio alg1:\\t\", mean_iter_alg1)\n",
    "    print(\"Convergencia:\\t\\t\", flag,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 5000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de cuadrática 1:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de las funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = lambda n: n*np.eye(n) + np.ones((n,n))\n",
    "matrix2 = lambda n: np.fromfunction(lambda i, j: np.exp(-0.25*(i - j)**2), (n, n))\n",
    "\n",
    "A11 = matrix1(10)\n",
    "A12 = matrix1(100)\n",
    "A13 = matrix1(1000)\n",
    "b1 = np.ones(10)\n",
    "b2 = np.ones(100)\n",
    "b3 = np.ones(1000) \n",
    "\n",
    "f_square11 = lambda x: 0.5*x.T@A11@x-b1@x\n",
    "gradf_square11 = lambda x: A11@x-b1\n",
    "hessf_square11 = lambda x: A11\n",
    "\n",
    "f_square12 = lambda x: 0.5*x.T@A12@x-b2@x\n",
    "gradf_square12 = lambda x: A12@x-b2\n",
    "hessf_square12 = lambda x: A12\n",
    "\n",
    "f_square13 = lambda x: 0.5*x.T@A13@x-b3@x\n",
    "gradf_square13 = lambda x: A13@x-b3\n",
    "hessf_square13 = lambda x: A13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t10\n",
      "f(x0):\t\t\t0.0\n",
      "Número de iteraciones:\t1\n",
      "f(xk):\t\t\t-0.24999999999999983\n",
      "Solución:\t\t 0.05,0.05,0.05,0.05 ,..., 0.05,0.05,0.05,0.05\n",
      "||gk||:\t\t\t 6.280369834735101e-16\n",
      "Iter. promedio alg1:\t 1.0\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 =np.zeros(10)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(f_square11,gradf_square11,hessf_square11,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t100\n",
      "f(x0):\t\t\t0.0\n",
      "Número de iteraciones:\t1\n",
      "f(xk):\t\t\t-0.24999999999999994\n",
      "Solución:\t\t 0.005,0.005,0.005,0.005 ,..., 0.005,0.005,0.005,0.005\n",
      "||gk||:\t\t\t 1.538370149106851e-15\n",
      "Iter. promedio alg1:\t 1.0\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 =np.zeros(100)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(f_square12,gradf_square12,hessf_square12,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t1000\n",
      "f(x0):\t\t\t0.0\n",
      "Número de iteraciones:\t1\n",
      "f(xk):\t\t\t-0.2500000000000002\n",
      "Solución:\t\t 0.0005,0.0005,0.0005,0.0005 ,..., 0.0005,0.0005,0.0005,0.0005\n",
      "||gk||:\t\t\t 2.438504729062236e-13\n",
      "Iter. promedio alg1:\t 1.0\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 =np.zeros(1000)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(f_square13,gradf_square13,hessf_square13,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de cuadrática 2:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A21 = matrix2(10)\n",
    "A22 = matrix2(100)\n",
    "A23 = matrix2(1000)\n",
    "\n",
    "f_square21 = lambda x: 0.5*x.T@A21@x-b1@x\n",
    "gradf_square21 = lambda x: A21@x-b1\n",
    "hessf_square21 = lambda x: A21\n",
    "\n",
    "f_square22 = lambda x: 0.5*x.T@A22@x-b2@x\n",
    "gradf_square22 = lambda x: A22@x-b2\n",
    "hessf_square22 = lambda x: A22\n",
    "\n",
    "f_square23 = lambda x: 0.5*x.T@A23@x-b3@x\n",
    "gradf_square23 = lambda x: A23@x-b3\n",
    "hessf_square23 = lambda x: A23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t10\n",
      "f(x0):\t\t\t0.0\n",
      "Número de iteraciones:\t1\n",
      "f(xk):\t\t\t-1.7934208025263507\n",
      "Solución:\t\t 1.3690991585471464,-1.166376817178349,1.6090828050291892,-0.6133905258859524 ,..., -0.6133905258860959,1.6090828050289954,-1.1663768171785018,1.3690991585470598\n",
      "||gk||:\t\t\t 5.448880297293939e-12\n",
      "Iter. promedio alg1:\t 5.0\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(10)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(f_square21,gradf_square21,hessf_square21,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t100\n",
      "f(x0):\t\t\t0.0\n",
      "Número de iteraciones:\t2\n",
      "f(xk):\t\t\t-14.494330955892167\n",
      "Solución:\t\t 1.4462811226673538,-1.4163346315646115,2.110458774736036,-1.4249737816284258 ,..., -1.4249830863371584,2.1104637591612976,-1.416327887521777,1.446276263768653\n",
      "||gk||:\t\t\t 4.400008993296028e-05\n",
      "Iter. promedio alg1:\t 57.0\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(100)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(f_square22,gradf_square22,hessf_square22,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t1000\n",
      "f(x0):\t\t\t0.0\n",
      "Número de iteraciones:\t1\n",
      "f(xk):\t\t\t-141.43698703562052\n",
      "Solución:\t\t 1.446288242264973,-1.4163595431324436,2.11051809682915,-1.4250723051291694 ,..., -1.4250723051291925,2.110518096829142,-1.4163595431324532,1.4462882422649672\n",
      "||gk||:\t\t\t 0.00018766135270268977\n",
      "Iter. promedio alg1:\t 262.0\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(1000)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(f_square23,gradf_square23,hessf_square23,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Función de Beale :** \n",
    "- $\\mathbf{x}_0 = (2,3)$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t2\n",
      "f(x0):\t\t\t3347.203125\n",
      "Número de iteraciones:\t12\n",
      "f(xk):\t\t\t1.2565554914089834e-15\n",
      "Solución:\t\t [2.99999992 0.49999998]\n",
      "||gk||:\t\t\t 1.8570760269371032e-07\n",
      "Iter. promedio alg1:\t 1.4166666666666667\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2.0,3.0])\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(opti.fncBeale,opti.grad_fncBeale,opti.hess_fncBeale,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de Himmelblau:**\n",
    "\n",
    "- $\\mathbf{x}_0 = (2,4)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t2\n",
      "f(x0):\t\t\t130.0\n",
      "Número de iteraciones:\t6\n",
      "f(xk):\t\t\t7.394064262118014e-23\n",
      "Solución:\t\t [3. 2.]\n",
      "||gk||:\t\t\t 6.758096355951128e-11\n",
      "Iter. promedio alg1:\t 2.0\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2.0,4.0])\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(opti.fncHimmelblau,opti.grad_fncHimmelblau,opti.hess_fncHimmelblau,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de Rosenbrock:** \n",
    "\n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0)\\in \\mathbb{R}^{2}$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t2\n",
      "f(x0):\t\t\t24.199999999999996\n",
      "Número de iteraciones:\t21\n",
      "f(xk):\t\t\t1.4808987231782003e-12\n",
      "Solución:\t\t [0.99999878 0.99999756]\n",
      "||gk||:\t\t\t 1.0876244840528185e-06\n",
      "Iter. promedio alg1:\t 1.9523809523809523\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2,1.0])\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(opti.fncRosenbrock,opti.grad_fncRosenbrock,opti.hess_fncRosenbrock,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{20}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t20\n",
      "f(x0):\t\t\t4598.0\n",
      "Número de iteraciones:\t42\n",
      "f(xk):\t\t\t3.986623854261404\n",
      "Solución:\t\t -0.9932860947283889,0.9966510520107768,0.9983303033514849,0.9991677271862901 ,..., 0.9999985199523841,0.9999971763718556,0.9999944051894056,0.9999888019347066\n",
      "||gk||:\t\t\t 1.4995878862774756e-05\n",
      "Iter. promedio alg1:\t 14.857142857142858\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2,1.0]*10)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(opti.fncRosenbrock,opti.grad_fncRosenbrock,opti.hess_fncRosenbrock,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{40}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión:\t\t40\n",
      "f(x0):\t\t\t9680.000000000004\n",
      "Número de iteraciones:\t77\n",
      "f(xk):\t\t\t3.9866238543032533\n",
      "Solución:\t\t -0.9932861010095073,0.9966510748305946,0.9983303199019564,0.9991677381035983 ,..., 0.9999997137741619,0.9999994249134465,0.9999988430341576,0.9999976668930461\n",
      "||gk||:\t\t\t 2.5185493711510602e-05\n",
      "Iter. promedio alg1:\t 18.051948051948052\n",
      "Convergencia:\t\t True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2,1.0]*20)\n",
    "n = len(x0)\n",
    "tol = np.sqrt(n)*(np.finfo(float).eps)**(1/3)\n",
    "test_line_search_NewtonGC(opti.fncRosenbrock,opti.grad_fncRosenbrock,opti.hess_fncRosenbrock,x0,tol,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"8C3061\" >**Ejercicio 2 (3.0 puntos)**</font>\n",
    "\n",
    "Programar las funciones que calcule el gradiente y la Hessiana usando el método\n",
    "de diferencias finitas.\n",
    "\n",
    "1. Programe la función que calcule una aproximación del gradiente de una función\n",
    "   $f(\\mathbf{x})$ en un punto $\\mathbf{x}\\in\\mathbb{R}^n$ dado usando el esquema de \n",
    "   diferencias finitas hacia adelante    (Página 20 de la Clase 20).\n",
    "   \n",
    "- La función recibe como parámetros la función $f$, el punto $\\mathbf{x}$ y\n",
    "  el incremento $h$ y devuelve el arreglo de tamaño $n$ con las aproximaciones\n",
    "  de  aproximaciones de las derivadas parciales en el punto $\\mathbf{x}$.\n",
    "  \n",
    "2. Programe la función que calcule una aproximación de la Hessiana de una función\n",
    "   $f(\\mathbf{x})$ en un punto $\\mathbf{x}\\in\\mathbb{R}^n$ dado usando el esquema de \n",
    "   diferencias finitas de la Página 22  de la Clase 20.\n",
    "\n",
    "- La función recibe como parámetros la función $f$, el punto $\\mathbf{x}$ y\n",
    "  el incremento $h$ y devuelve una matriz simétrica de tamaño $n$ que tiene\n",
    "  las aproximaciones de las segundas derivadas parciales de $f$  en el punto $\\mathbf{x}$.\n",
    "  \n",
    "3. Modifique la función `errorRelativo_grad`  para reportar estadísticas del\n",
    "   error relativo de la implementación del gradiente analítico `gradf` de \n",
    "   una función respecto al gradiente calculado con `autograd`, para que mida \n",
    "   el error relativo entre la función `gradf` y la aproximación del gradiente \n",
    "   usando diferencias finitas.\n",
    "   Hay que agregar como parámetro de `errorRelativo_grad` el incremento $h$\n",
    "   para que se pueda llamar la función del Punto 1.\n",
    "   \n",
    "4. Programar la función `errorRelativo_hess`, similar a la función del punto anterior,\n",
    "   para que reporte estadísticas del error relativo entre una función que calcula\n",
    "   la Hessiana de $f$ de manera analítica en un punto  $\\mathbf{x}$ y la aproximación\n",
    "   de la Hessiana en  $\\mathbf{x}$ usando diferencias finitas.\n",
    "   \n",
    "5. Pruebe las funciones `errorRelativo_grad` con cada una de las funciones \n",
    "   del Ejercicio 1 usando $h=10^{-5}, 10^{-6}, 10^{-7}, 10^{-8}$.\n",
    "   ¿Cuál es el valor de $h$ que conviene usar para aproximar el gradiente y cuál\n",
    "   para aproximar la Hessiana?\n",
    "\n",
    "### Solución:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementación de la aproximación del gradiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_aprox(f:Callable[[np.array],float],x:np.ndarray,h:float)->np.array:\n",
    "    \"\"\"Compute the gradient approximation\n",
    "    \n",
    "    :param f: function (Callable[[np.array],float])\n",
    "    :param x: point (np.array)\n",
    "    :param h: step size (float)\n",
    "        \n",
    "    :return: gradient approximation (np.array)\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    e=np.eye(n)\n",
    "    grad = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        grad[i] = (f(x+h*e[i])-f(x-h*e[i]))/(2*h)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implementación de la aproximación de la hessiana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hess_aprox(f:Callable[[np.array],float],x:np.ndarray,h:float)->np.array:\n",
    "    \"\"\"Compute the hessian approximation\n",
    "    \n",
    "    :param f: function\n",
    "    :param x: point\n",
    "    :param h: step\n",
    "    \n",
    "    :return: hessian approximation\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    hess = np.zeros((n,n))\n",
    "    e = np.eye(n) \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            hess[i,j] = (f(x+h*e[i]+h*e[j])-f(x+h*e[i])-f(x+h*e[j])+f(x))/(h**2)\n",
    "    \n",
    "    hess+=hess.T\n",
    "    for i in range(n):\n",
    "        hess[i,i] = (f(x+2*h*e[i])-2*f(x+h*e[i])+f(x))/(h**2)\n",
    "    return hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Error relativo de la aproximación del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorRelativo_grad(fncf:Callable[[np.array], float], \n",
    "                       gradf:Callable[[np.array], np.array],\n",
    "                       gradf_approx: Callable[[np.array], np.array],\n",
    "                       h:float,\n",
    "                       n:int,\n",
    "                       nt:int):\n",
    "    \n",
    "    \"\"\"Compute the relative error of the gradient approximation and the gradient\n",
    "    :param fncf: function\n",
    "    :rtype fncf: Callable[[np.array], float]\n",
    "    :param gradf: gradient\n",
    "    :rtype gradf: Callable[[np.array], np.array]\n",
    "    :param gradf_approx: gradient approximation\n",
    "    :rtype gradf_approx: Callable[[np.array], np.array]\n",
    "    :param h: step\n",
    "    :rtype h: float\n",
    "    :param n: dimension\n",
    "    :rtype n: int\n",
    "    :param nt: number of tests\n",
    "    :rtype nt: int\n",
    "    \"\"\"\n",
    "    \n",
    "    ve = np.zeros(nt)\n",
    "    #print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "    # Funcion gradiente generada con autograd\n",
    "    \n",
    "    for it in range(nt):\n",
    "        x0  = np.random.randn(n)\n",
    "        g0  = gradf(x0)\n",
    "        ga  = gradf_approx(fncf,x0,h)\n",
    "        ve[it] = np.linalg.norm(g0-ga)/np.linalg.norm(g0)\n",
    "    \n",
    "    print('h: %.2e   Min: %.2e   Media: %.2e    Max: %.2e' %(h,np.min(ve), np.mean(ve), np.max(ve)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Error relativo de la aproximación de la hessiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorRelativo_hess(fncf:Callable[[np.array], float], \n",
    "                       hessf:Callable[[np.array], np.array],\n",
    "                       hessf_approx: Callable[[np.array], np.array],\n",
    "                       h:float,\n",
    "                       n:int,\n",
    "                       nt:int):\n",
    "    \n",
    "    \"\"\"Compute the relative error of the gradient approximation and the gradient\n",
    "    :param fncf: function\n",
    "    :rtype fncf: Callable[[np.array], float]\n",
    "    :param gradf: gradient\n",
    "    :rtype gradf: Callable[[np.array], np.array]\n",
    "    :param gradf_approx: gradient approximation\n",
    "    :rtype gradf_approx: Callable[[np.array], np.array]\n",
    "    :param h: step\n",
    "    :rtype h: float\n",
    "    :param n: dimension\n",
    "    :rtype n: int\n",
    "    :param nt: number of tests\n",
    "    :rtype nt: int\n",
    "    \"\"\"\n",
    "    \n",
    "    ve = np.zeros(nt)\n",
    "    #print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "    # Funcion gradiente generada con autograd\n",
    "    \n",
    "    for it in range(nt):\n",
    "        x0  = np.random.randn(n)\n",
    "        g0  = hessf(x0)\n",
    "        ga  = hessf_approx(fncf,x0,h)\n",
    "        ve[it] = np.linalg.norm(g0-ga)/np.linalg.norm(g0)\n",
    "    print('h: %.2e   Min: %.2e   Media: %.2e    Max: %.2e' %(h,np.min(ve), np.mean(ve), np.max(ve)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Errores relativos de la aproximación del gradiente y la hessiana en las funciones de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de cuadrática 1:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 1.06e-11   Media: 3.79e-11    Max: 1.17e-10\n",
      "h: 1.00e-06   Min: 1.37e-10   Media: 3.70e-10    Max: 1.09e-09\n",
      "h: 1.00e-07   Min: 1.31e-09   Media: 3.61e-09    Max: 7.55e-09\n",
      "h: 1.00e-08   Min: 1.25e-08   Media: 3.80e-08    Max: 8.59e-08\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 1.70e+00   Media: 3.15e+00    Max: 4.92e+00\n",
      "h: 1.00e-06   Min: 2.13e+00   Media: 3.34e+00    Max: 5.72e+00\n",
      "h: 1.00e-07   Min: 1.68e+00   Media: 3.16e+00    Max: 4.40e+00\n",
      "h: 1.00e-08   Min: 1.73e+00   Media: 3.19e+00    Max: 5.33e+00\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(10)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(f_square11,gradf_square11,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(f_square11,gradf_square11,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(f_square11,gradf_square11,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(f_square11,gradf_square11,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(f_square11,hessf_square11,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(f_square11,hessf_square11,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(f_square11,hessf_square11,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(f_square11,hessf_square11,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 1.46e-10   Media: 4.69e-10    Max: 1.23e-09\n",
      "h: 1.00e-06   Min: 1.84e-09   Media: 4.27e-09    Max: 8.85e-09\n",
      "h: 1.00e-07   Min: 2.17e-08   Media: 3.88e-08    Max: 9.73e-08\n",
      "h: 1.00e-08   Min: 1.79e-07   Media: 3.98e-07    Max: 1.16e-06\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 8.15e+00   Media: 1.00e+01    Max: 1.19e+01\n",
      "h: 1.00e-06   Min: 8.81e+00   Media: 1.02e+01    Max: 1.21e+01\n",
      "h: 1.00e-07   Min: 8.46e+00   Media: 9.88e+00    Max: 1.12e+01\n",
      "h: 1.00e-08   Min: 8.63e+00   Media: 1.01e+01    Max: 1.21e+01\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(100)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(f_square12,gradf_square12,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(f_square12,gradf_square12,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(f_square12,gradf_square12,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(f_square12,gradf_square12,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(f_square12,hessf_square12,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(f_square12,hessf_square12,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(f_square12,hessf_square12,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(f_square12,hessf_square12,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 1.73e-09   Media: 4.76e-09    Max: 1.89e-08\n",
      "h: 1.00e-06   Min: 1.66e-08   Media: 4.08e-08    Max: 1.22e-07\n",
      "h: 1.00e-07   Min: 1.49e-07   Media: 4.30e-07    Max: 1.80e-06\n",
      "h: 1.00e-08   Min: 1.68e-06   Media: 4.02e-06    Max: 1.34e-05\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(1000)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(f_square13,gradf_square13,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(f_square13,gradf_square13,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(f_square13,gradf_square13,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(f_square13,gradf_square13,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de cuadrática 2:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 5.88e-12   Media: 2.54e-11    Max: 7.44e-11\n",
      "h: 1.00e-06   Min: 8.56e-11   Media: 3.20e-10    Max: 9.67e-10\n",
      "h: 1.00e-07   Min: 6.74e-10   Media: 2.93e-09    Max: 6.27e-09\n",
      "h: 1.00e-08   Min: 5.94e-09   Media: 2.68e-08    Max: 6.51e-08\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 1.46e+00   Media: 3.94e+00    Max: 8.38e+00\n",
      "h: 1.00e-06   Min: 9.96e-01   Media: 3.57e+00    Max: 6.59e+00\n",
      "h: 1.00e-07   Min: 1.29e+00   Media: 3.92e+00    Max: 8.55e+00\n",
      "h: 1.00e-08   Min: 1.47e+00   Media: 3.84e+00    Max: 9.02e+00\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(10)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(f_square21,gradf_square21,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(f_square21,gradf_square21,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(f_square21,gradf_square21,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(f_square21,gradf_square21,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(f_square21,hessf_square21,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(f_square21,hessf_square21,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(f_square21,hessf_square21,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(f_square21,hessf_square21,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 1.04e-10   Media: 1.78e-10    Max: 2.85e-10\n",
      "h: 1.00e-06   Min: 1.24e-09   Media: 1.80e-09    Max: 3.06e-09\n",
      "h: 1.00e-07   Min: 1.29e-08   Media: 1.74e-08    Max: 2.93e-08\n",
      "h: 1.00e-08   Min: 1.15e-07   Media: 1.68e-07    Max: 2.53e-07\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 8.25e+00   Media: 1.20e+01    Max: 1.47e+01\n",
      "h: 1.00e-06   Min: 7.26e+00   Media: 1.13e+01    Max: 1.54e+01\n",
      "h: 1.00e-07   Min: 8.27e+00   Media: 1.19e+01    Max: 1.59e+01\n",
      "h: 1.00e-08   Min: 8.23e+00   Media: 1.18e+01    Max: 1.61e+01\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(100)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(f_square22,gradf_square22,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(f_square22,gradf_square22,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(f_square22,gradf_square22,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(f_square22,gradf_square22,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(f_square22,hessf_square22,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(f_square22,hessf_square22,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(f_square22,hessf_square22,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(f_square22,hessf_square22,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 9.43e-10   Media: 1.62e-09    Max: 2.66e-09\n",
      "h: 1.00e-06   Min: 1.01e-08   Media: 1.60e-08    Max: 2.41e-08\n",
      "h: 1.00e-07   Min: 9.97e-08   Media: 1.59e-07    Max: 2.64e-07\n",
      "h: 1.00e-08   Min: 1.04e-06   Media: 1.58e-06    Max: 2.71e-06\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(1000)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(f_square23,gradf_square23,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(f_square23,gradf_square23,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(f_square23,gradf_square23,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(f_square23,gradf_square23,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Función de Beale :** \n",
    "- $\\mathbf{x}_0 = (2,3)$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 5.87e-12   Media: 4.95e-11    Max: 3.46e-10\n",
      "h: 1.00e-06   Min: 2.84e-11   Media: 1.08e-10    Max: 2.57e-10\n",
      "h: 1.00e-07   Min: 1.33e-10   Media: 1.22e-09    Max: 3.69e-09\n",
      "h: 1.00e-08   Min: 1.34e-09   Media: 1.21e-08    Max: 7.52e-08\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 4.91e-01   Media: 1.73e+00    Max: 3.27e+00\n",
      "h: 1.00e-06   Min: 4.20e-01   Media: 1.73e+00    Max: 3.69e+00\n",
      "h: 1.00e-07   Min: 5.57e-01   Media: 1.72e+00    Max: 3.63e+00\n",
      "h: 1.00e-08   Min: 6.03e-01   Media: 1.51e+00    Max: 3.53e+00\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2,3])\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(opti.fncBeale,opti.grad_fncBeale,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(opti.fncBeale,opti.grad_fncBeale,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(opti.fncBeale,opti.grad_fncBeale,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(opti.fncBeale,opti.grad_fncBeale,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(opti.fncBeale,opti.hess_fncBeale,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(opti.fncBeale,opti.hess_fncBeale,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(opti.fncBeale,opti.hess_fncBeale,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(opti.fncBeale,opti.hess_fncBeale,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de Himmelblau:**\n",
    "\n",
    "- $\\mathbf{x}_0 = (2,4)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 1.11e-12   Media: 5.29e-11    Max: 4.01e-10\n",
      "h: 1.00e-06   Min: 6.86e-11   Media: 5.57e-10    Max: 5.45e-09\n",
      "h: 1.00e-07   Min: 4.12e-10   Media: 3.97e-09    Max: 2.06e-08\n",
      "h: 1.00e-08   Min: 2.87e-09   Media: 4.36e-08    Max: 3.48e-07\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 6.87e-01   Media: 2.35e+00    Max: 1.13e+01\n",
      "h: 1.00e-06   Min: 7.14e-01   Media: 1.67e+00    Max: 4.71e+00\n",
      "h: 1.00e-07   Min: 6.66e-01   Media: 1.85e+00    Max: 5.21e+00\n",
      "h: 1.00e-08   Min: 6.54e-01   Media: 1.88e+00    Max: 4.57e+00\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2,3])\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(opti.fncHimmelblau,opti.grad_fncHimmelblau,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(opti.fncHimmelblau,opti.grad_fncHimmelblau,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(opti.fncHimmelblau,opti.grad_fncHimmelblau,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(opti.fncHimmelblau,opti.grad_fncHimmelblau,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(opti.fncHimmelblau,opti.hess_fncHimmelblau,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(opti.fncHimmelblau,opti.hess_fncHimmelblau,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(opti.fncHimmelblau,opti.hess_fncHimmelblau,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(opti.fncHimmelblau,opti.hess_fncHimmelblau,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de Rosenbrock:** \n",
    "\n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0)\\in \\mathbb{R}^{2}$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 3.27e-12   Media: 3.26e-10    Max: 5.61e-09\n",
      "h: 1.00e-06   Min: 4.73e-12   Media: 5.71e-11    Max: 2.44e-10\n",
      "h: 1.00e-07   Min: 7.51e-11   Media: 7.12e-10    Max: 2.26e-09\n",
      "h: 1.00e-08   Min: 1.07e-09   Media: 6.39e-09    Max: 1.78e-08\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 4.06e-01   Media: 1.13e+00    Max: 1.75e+00\n",
      "h: 1.00e-06   Min: 4.98e-01   Media: 1.09e+00    Max: 1.97e+00\n",
      "h: 1.00e-07   Min: 4.66e-01   Media: 1.18e+00    Max: 2.06e+00\n",
      "h: 1.00e-08   Min: 5.87e-01   Media: 1.22e+00    Max: 2.22e+00\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2,1.0])\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{20}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 2.28e-11   Media: 4.31e-11    Max: 7.65e-11\n",
      "h: 1.00e-06   Min: 1.43e-10   Media: 2.43e-10    Max: 3.87e-10\n",
      "h: 1.00e-07   Min: 7.96e-10   Media: 2.38e-09    Max: 4.49e-09\n",
      "h: 1.00e-08   Min: 1.28e-08   Media: 2.24e-08    Max: 3.75e-08\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 1.93e+00   Media: 3.11e+00    Max: 4.98e+00\n",
      "h: 1.00e-06   Min: 1.90e+00   Media: 3.11e+00    Max: 4.77e+00\n",
      "h: 1.00e-07   Min: 1.89e+00   Media: 3.20e+00    Max: 4.74e+00\n",
      "h: 1.00e-08   Min: 2.00e+00   Media: 3.11e+00    Max: 5.45e+00\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2,1.0]*10)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{40}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errores relativos en el cálculo del gradiente:\n",
      "h: 1.00e-05   Min: 3.44e-11   Media: 5.27e-11    Max: 8.81e-11\n",
      "h: 1.00e-06   Min: 2.88e-10   Media: 4.55e-10    Max: 1.03e-09\n",
      "h: 1.00e-07   Min: 2.51e-09   Media: 4.26e-09    Max: 6.86e-09\n",
      "h: 1.00e-08   Min: 2.17e-08   Media: 4.35e-08    Max: 8.76e-08\n",
      "\n",
      "Errores relativos en el cálculo de la hessiana:\n",
      "h: 1.00e-05   Min: 3.25e+00   Media: 4.81e+00    Max: 7.19e+00\n",
      "h: 1.00e-06   Min: 3.04e+00   Media: 4.69e+00    Max: 6.66e+00\n",
      "h: 1.00e-07   Min: 2.97e+00   Media: 4.76e+00    Max: 6.31e+00\n",
      "h: 1.00e-08   Min: 3.49e+00   Media: 4.64e+00    Max: 8.03e+00\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2,1.0]*20)\n",
    "n = len(x0)\n",
    "nt=50\n",
    "\n",
    "print('\\nErrores relativos en el cálculo del gradiente:')\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_grad(opti.fncRosenbrock,opti.grad_fncRosenbrock,grad_aprox,1e-8,n,nt)\n",
    "\n",
    "print('\\nErrores relativos en el cálculo de la hessiana:')\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-5,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-6,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-7,n,nt)\n",
    "errorRelativo_hess(opti.fncRosenbrock,opti.hess_fncRosenbrock,grad_aprox,1e-8,n,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según lo que se observa en las pruebas con las funciones de testeo viene siendo que el mejor valor de $h$ es $1e-5$ de manera rotunda al ser mejor que los otros tamaños de paso con excepción de un caso. Por otra parte, se observa que hay cierta tendencia para el valor de $1e-6$ para $h$ presenta un sútil mejor comportamiento, no es tan estable y hay que comentar que el error en todos los casos es muy alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# <font color=\"8C3061\" >**Ejercicio 3 (3.0 puntos)**\n",
    "\n",
    "Seleccionar un artículo para el proyecto final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:**\n",
    "\n",
    "Mario Alberto Tapia de la Cruz (maestría en matemáticas aplicadas)\n",
    "Edison David Serrano Cárdenas (maestría en matemáticas aplicadas)\n",
    "\n",
    "A family of hybrid conjugate gradient method with restart procedure for unconstrained optimizations and image restorations.\n",
    "Xianzhen Jiang, Xiaomin Ye, Zefeng Huang, Meixing Liu. 2023\n",
    "https://drive.google.com/file/d/1h1TQpydDxkYBF0G_jd7O7-9J69X-V-dI/view?usp=sharing\n",
    "\n",
    "Alcance del proyecto: El proyecto cuenta unicamente con un algoritmo, por lo que se hará la implementación del mismo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
